[["index.html", "Practical 2 - Understanding correlation and further exploring relationships 1 Intro 1.1 Intended Learning Outcomes 1.2 Introduction", " Practical 2 - Understanding correlation and further exploring relationships Team in Room 420 - Megan Ruffle, Naphon Olley, Jennifer James, William Ryan 1 Intro 1.1 Intended Learning Outcomes After attending this lab, you should be able to use R to: calculate least squares estimates of model parameters using vector-matrix formulation; calculate and interpret the sample correlation coefficient; perform hypothesis tests on the population correlation and interpret the decision. 1.2 Introduction In the lectures we learned how to assess the strength of a linear relationship between random variables using the correlation coefficient. The population correlation is a measure of the magnitude of the strength of the relationship between two random variables X and Y, and is defined as \\[\\begin{equation} \\rho(X,Y) = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}}, \\tag{1.1} \\end{equation}\\] and can be estimated by replacing each of \\(\\text{Cov}(X,Y)\\), (X) and (Y) by their unbiased estimators to give \\[\\begin{equation} r = \\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}=\\frac{\\sum^{n}_{i=1}(x_i-\\overline{x})(y_i-\\overline{y})}{\\sqrt{\\sum^{n}_{i=1}(x_i-\\overline{x})^2(y_i-\\overline{y})^2}}, \\tag{1.2} \\end{equation}\\] the sample correlation coefficient (-1 \\(\\le r \\le\\) 1). Given a sample of data, we can assess the statistical significance of the observed correlations between variables in the wider population. To do this we perform a hypothesis test (more on this in Chapter 2.2). "],["examples.html", "2 Examples 2.1 Example 1 - crime dataset 2.2 Example 2 - phys dataset 2.3 Calculating the correlation by hand", " 2 Examples 2.1 Example 1 - crime dataset Use pairs to visualise the data and determine which predictors may be useful in predicting Crime. Hint The R command pairs() may be used to see the relationships between all variables. Solution crime &lt;- read.csv(&quot;crime.csv&quot;) pairs(crime[,-1], lower.panel = NULL) # We add [,-1] to the end of crime to remove the first column which has non-numeric arguments (state names) Build a simple linear regression model against Dropout and interpret estimated coefficients. According to the model, when Dropout is equal to 0, Crime would be roughly 200022002400. For each 1 unit increase in the Dropout variable, Crime would go up by roughly (to 4 decimal places). Solution model1 &lt;- lm(Crime ~ Dropout, data = crime) coef(model1) ## (Intercept) Dropout ## 2196.5435 281.7613 Calculate the least squares estimates of model parameters using the vector-matrix formulation. Hint The following R commands will come in uesful: model.matrix # returns the design matrix t # gets the transpose of a vector or matrix %*% # multiplies matrices together solve # computes the inverse of a matrix Recall the least squares estimate of the model parameters in terms of vector-matrix notation is given by \\[\\begin{equation} \\hat{\\beta}=(X^{T}X)^{-1}X^{T}Y \\tag{1.1} \\end{equation}\\] Solution X &lt;- model.matrix(~ Dropout, data = crime) XtX &lt;- t(X) %*% X # The inverse of XtX can be found by using solve(XtX) Y &lt;- crime$Crime XtY &lt;- t(X) %*% Y beta.hat &lt;- solve(XtX) %*% XtY beta.hat ## [,1] ## (Intercept) 2196.5435 ## Dropout 281.7613 Check this is same as the results computed using the summation notation (discussed in Practical 1). Hint Recall that the equations for the least square estimates using the summation notation are \\[\\begin{equation} \\hat{\\beta}_0= \\overline{Y}-\\hat{\\beta}_1 \\overline{x} \\tag{2.1} \\end{equation}\\] and \\[\\begin{equation} \\hat{\\beta}_1= \\frac{\\sum^n_{i=1}(x_i-\\overline{x})(Y_i-\\overline{Y})}{\\sum^n_{i=1}(x_i-\\overline{x})^2} \\tag{2.2} \\end{equation}\\] Solution Y &lt;- crime$Crime x &lt;- crime$Dropout b1 &lt;- sum((x - mean(x)) * (Y - mean(Y)))/sum((x - mean(x))^2) b0 &lt;- mean(Y) - b1 * mean(x) Use 1 or more predictors alongside Dropout to build a multiple linear regression model for explaining Crime. Hint Use the graph found using the pairs() command in a) to select predictors that appear suitable for describing Crime. Recall that a multiple linear regression model can be constructed using model &lt;- lm(Crime ~ Dropout + Predictor1 + Predictor2 + ..., data = crime) Calculate the least squares estimates of parameters using the vector-matrix formulation in the new multiple linear regression model. Solution The same steps can be followed as in c), but the design matrix X has to be updated accordingly. Say we want to add Police and Prison variables to our model. We would then use the following code. X &lt;- model.matrix(~ Dropout + Police + Prison, data = crime) XtX &lt;- t(X) %*% X # The inverse of XtX can be found by using solve(XtX) Y &lt;- crime$Crime XtY &lt;- t(X) %*% Y beta.hat &lt;- solve(XtX) %*% XtY beta.hat ## [,1] ## (Intercept) 1513.317509 ## Dropout 148.343452 ## Police 4.782505 ## Prison 2.794514 2.2 Example 2 - phys dataset Recall Example 1 from Practical 1 in which volunteers had their power output (in watts), weight, and leg length measurements recorded. Here we would like to assess the strength of the relationship, if any, between Power Output and Weight, which we explored in scatterplots in the previous practical, displayed in Figure 1. We are going to do this for male and female volunteers separately, such that we assess the statistical significance of the observed correlation between these two variables in the wider populations of (i) males and (ii) females. Figure 2.1: Scatterplot of Power Output versus Weight. Firstly, we subset the data for males and females. One way to do this is: physM &lt;- subset(phys, Gender == \"Male\", data = phys) physF &lt;- subset(phys, Gender == \"Female\", data = phys) We now perform, separately for males and females, the following hypothesis test: \\(H_0: \\rho=0\\) vs. \\(H_1:\\rho \\ne 0\\) We test the null hypothesis, \\(H_0\\), that is, that in the population of males/females the correlation between Power Output and Weight is 0 against the alternative hypothesis, \\(H_1\\), that the correlation is not equal to 0. To compute the sample correlation coefficient, \\(r\\), and perform our hypothesis test, we use the cor.test command. For the males data, the command is as follows: cor.test(physM$Power1, physM$Weight) Note: in the cor.test command the $ notation is required to access the variables from the subsetted data. The hypothesis test produces a p-value, where we reject the null hypothesis, \\(H_0\\), for small values of the p-value (typically p-values &lt; 0.05). It also produces a 95% confidence interval for a range of plausible values for the true population correlation. What is the sample correlation coefficient for the males data? (to 4 decimal places) What is the p-value for the test? (to 6 decimal places) The sample correlation coefficient tells us that Power Output and Weight have a weakstrong, negativepositive relationship. Based on the p-value of the test, we would reject the null hypothesisfail to reject the null hypothesis. Perform the same test on the Female data. What is the sample correlation coefficient for the females data? (to 4 decimal places) What is the p-value for the test? (to 4 decimal places) The sample correlation coefficient tells us that Power Output and Weight have a weakstrong, negativepositive relationship. Based on the p-value of the test, we would reject the null hypothesisfail to reject the null hypothesis. Note: if we do not subset the data by gender, we obtain a sample correlation coefficient \\(r = 0.89\\), with a p-value \\(\\lt\\) 0.05, and thus we would conclude that there is a strong, positive linear relationship between Power Output and Weight. However, we now know that is not the case for females. 2.3 Calculating the correlation by hand To compute the sample correlation coefficient, r, the command cor.test uses the formula given in (1.2). To check that the cor.test command is ‘correct’, we can ourselves calculate the correlation directly using the following commands: var # computes the variance of a given vector cov # computes the covariance between the vectors x and y sum # returns the sum of the values given mean # computes the mean of a given vector sqrt # computes the square-root of a given vector Give your answers to 3 decimal places where required. Using the commands var and cov, compute the variance and covariance given in (1.1) for the males data, where Y denotes the response variable Power Output, and X denotes the explanatory variable Weight. The variance of the explanatory variable Weight is . The variance of the response variable Power Output is . The covariance of the response and explanatory variables is . Solution X &lt;- physM$Weight Y &lt;- physM$Power1 var(X) ## [1] 47.37381 var(Y) ## [1] 25435.39 cov(X, Y) ## [1] 893.1468 Using the variance and covariance obtained in (a), and the square-root command, sqrt, compute the sample correlation coefficient using the formula given in (1.1) for the males data. Does this match what was obtained using the cor.test command? The sample correlation coefficient using the variance and covariance obtained in (a) is . This matchesdoes not match the sample correlation coefficient found using cor.test. Solution cov(X, Y)/sqrt(var(X)*var(Y)) ## [1] 0.8136441 cor.test(physM$Weight, physM$Power1)$estimate ## cor ## 0.8136441 Use the mean, sum, and sqrt commands to compute the sum of squares, \\(S_{xx}\\) and \\(S_{yy}\\), and the sum of products, \\(S_{xy}\\), given in formula (1.2) for the males data. Give your answers to 3 decimal places where required. \\(S_{xx}\\): \\(S_{yy}\\): \\(S_{xy}\\): Solution Sxx &lt;- sum((X-mean(X))^2) Syy &lt;- sum((Y-mean(Y))^2) Sxy &lt;- sum((X-mean(x))*(Y-mean(Y))) c(Sxx, Syy, Sxy) ## [1] 663.2333 356095.4916 12504.0557 Use the sum of squares and sum of products obtained in (c) to compute the sample correlation coefficient, \\(r\\), using formula (1.2) for the males data. Does this match your answers from (b) and the cor.test command? The sample correlation coefficient found using the sum of squares and sum of products above is , which is not the samethe same as the value found when using cor.test. Solution Sxy/sqrt(Sxx*Syy) ## [1] 0.8136441 "],["exercises.html", "3 Exercises 3.1 Exercise 1 - cheese dataset 3.2 Exercise 2 - Nicholas Cage data 3.3 Exercise 3 - Context: identifying relationships", " 3 Exercises 3.1 Exercise 1 - cheese dataset Choose the best two variables among (H2S, log(H2S), Lactic Acid, log(Lactic Acid)) to explain Taste and construct a multiple linear regression model using them. Hint The variable that best described a linear relationship with Taste was chosen he be log(H2S) in Practical 1. To choose a second variable, we can take another look at the plots created in Practical 1. # taste vs lactic acid plot(Taste ~ Lactic.Acid, data = cheese, xlab = &quot;Lactic acid concentration&quot;, ylab = &quot;Taste score&quot;) # taste vs H2S plot(Taste ~ H2S, data = cheese, xlab = &quot;H2S concentration&quot;, ylab = &quot;Taste score&quot;) # taste vs lactic acid plot(Taste ~ log(Lactic.Acid), data = cheese, xlab = &quot; Log lactic acid concentration&quot;, ylab = &quot;Taste score&quot;) # taste vs H2S plot(Taste ~ log(H2S), data = cheese, xlab = &quot;Log H2S concentration&quot;, ylab = &quot;Taste score&quot;) The 2 best variables to explain Taste are log(H2S) and H2SLactic Acidlog(Lactic Acid). Estimate the coefficients using the vector-matrix formulation and check they are same as the R output. Hint Remember to define the design matrix and the response vector correctly. Solution The R command to create the design matrix is designdesign.matrixmodelmodel.matrix Give your answers to 2 decimal places. The intercept is roughly . The coefficient describing the effect of log(H2S) is roughly . The coefficient describing the effect of Lactic Acid is roughly . Interpret the estimated coefficients. The model tells us that for every 1 unit increase in log(H2S), the Taste score goes up by roughly , when Lactic Acid remains the sameregardless of changes in Lactic Acid. Similarly, for every 1 unit increase in Lactic Acid, the Taste score goes up by roughly , when log(H2S) remains the sameregardless of changes in log(H2S. 3.2 Exercise 2 - Nicholas Cage data Hollywood legend Nicholas Cage seems to have a problem. It appears that every time he releases a new film upon the world many people drown by falling into pools of water. Coincidence? Or, are some of his films that bad? Data: Cage.csv Read in the data using: Cage &lt;- read.csv(\"Cage.csv\") Produce a scatterplot of NumDrowned (y) against NumFilms (x). Solution plot(NumDrowned ~ NumFilms, data = Cage, xlab = &quot;Number of Nicholas Cage films released in a year&quot;, ylab = &quot;Number of people who drowned falling into pools that year&quot;) Use the cor.test command to perform a correlation hypothesis test. What does this tell us about the relationship between NumDrowned and NumFilms? The sample correlation coefficient is (to 3 decimal places). According to the hypothesis test carried out, we fail to reject the null hypothesisreject the null hypothesis. This means we conclude the true correlation between the two variables is equal to 0not equal to zero. Solution cor.test(Cage$NumDrowned, Cage$NumFilms) ## ## Pearson&#39;s product-moment correlation ## ## data: Cage$NumDrowned and Cage$NumFilms ## t = 2.6785, df = 9, p-value = 0.02527 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.1101273 0.9045101 ## sample estimates: ## cor ## 0.6660043 This is an example of spurious correlation, where two variables that are not related to each other in any way, that is, they are independent, could be inferred as being related. The number of Nicholas Cage films released in a year is clearly not related to the number of drowning accidents in that same year, but if we just take our correlation hypothesis test on face value, then we would think otherwise. 3.3 Exercise 3 - Context: identifying relationships For the following contexts determine whether fitting a regression model would be appropriate. If a regression model is appropriate, identify which variable is the response variable and which is the explanatory variable. Is federal spending, on average, higher or lower in countries with high rates of poverty? Regression model appropriate? NoYes Federal spending: ExplanatoryResponse Poverty rates: ExplanatoryResponse A study was conducted to determine whether surgery or chemotherapy results in higher survival rates for a certain type of cancer. Regression model appropriate? NoYes Type of treatment: ExplanatoryResponse Survival rates: ExplanatoryResponse A study found that, overall, left-handed people die at a younger age than right-handed people. Regression model appropriate? NoYes Age of death: ExplanatoryResponse Left- or right-handed: ExplanatoryResponse Per capita cheese consumption is correlated with the number of people who died getting tangled in bed sheets. Regression model appropriate? NoYes Number of people who died getting tangled in bed sheets: ExplanatoryResponse Per capita cheese consumption: ExplanatoryResponse An experiment was conducted to test the effects of sleep deprivation on human reaction times. Regression model appropriate? NoYes Hours of sleep: ExplanatoryResponse Reaction times: ExplanatoryResponse A study was conducted in order to predict the GPA of university students given their high school GPA. Regression model appropriate? NoYes GPA of university students: ExplanatoryResponse High school GPA: ExplanatoryResponse A company wants to know if there is a significant relationship between its advertising expenditures and its sales volume. Regression model appropriate? NoYes Sales volume: ExplanatoryResponse Advertising expenditures: ExplanatoryResponse A sample of insured drivers with similar insurance policies were randomly selected. Interest is in determining whether there is a significant relationship between driving experience and insurance premium. Regression model appropriate? NoYes Driving experience: ExplanatoryResponse Insurance premium: ExplanatoryResponse Ice cream sales are correlated with murder rates in the US. Regression model appropriate? NoYes Murder rates: ExplanatoryResponse Ice cream sales: ExplanatoryResponse "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
